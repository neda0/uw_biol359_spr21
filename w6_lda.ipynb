{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "# Biol 359  |  Linear Discriminant Analysis\n",
    "### Spring 2021, Week 6\n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "The first 6 cells are the same as last week's activity. They still need to be run in order for this notebook to work, but are not the focus of this week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)}) \n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### Import breast cancer data \n",
    "Optional reference: https://pandas.pydata.org/docs/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "# NOTE:\n",
    "# `breast_raw.data`: Stores the raw data (breast feature data)\n",
    "# `breast_raw.feature_names`: Stores the raw data feature labels\n",
    "# `breast_raw.target`: Stores the tumor type (0 = 'benign', 1 = 'malignant')\n",
    "# `breast_raw.target_names`: Stores the tumor type labels ('benign' or 'malignant')\n",
    "# `breast_raw.DESCR`: Description of the data\n",
    "breast_raw = load_breast_cancer()\n",
    "\n",
    "# Uncomment the following line to print a description of the data\n",
    "print(breast_raw.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# Feature data set\n",
    "features = pd.DataFrame(breast_raw.data, columns=breast_raw.feature_names)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# Tumor label data set\n",
    "tumor = pd.DataFrame(breast_raw.target, columns=['tumor'])\n",
    "# tumor_set.replace({'tumor type': {0: 'benign', 1: 'malignant'}}, inplace=True)\n",
    "tumor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# Concantenate into one data frame\n",
    "breast = pd.concat([features, tumor], axis=1)\n",
    "# breast.loc[:, breast.columns != 'tumor'].head()\n",
    "# breast.loc[:, breast.columns == 'tumor'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "#### Assess feature data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "### Plotting our data! \n",
    "\n",
    "In the case where we have 30 dimensions, we would have to make plots...below are four for an example of how we could plot each of the features against one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots of the various features\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "features.plot.scatter(ax=axs[0, 0], x=\"mean radius\", y=\"mean area\", alpha=0.5, color='red');\n",
    "features.plot.scatter(ax=axs[0, 1], x=\"mean radius\", y=\"mean texture\", alpha=0.5, color='green');\n",
    "features.plot.scatter(ax=axs[1, 0], x=\"mean concave points\", y=\"mean concavity\", alpha=0.5, color='blue');\n",
    "features.plot.scatter(ax=axs[1, 1], x=\"mean concave points\", y=\"mean fractal dimension\", alpha=0.5, color='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another popular method is to use a Pair Plot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_feats = 6\n",
    "g = sns.pairplot(data=breast, corner=True, vars=features.columns.to_list()[0:num_feats], \n",
    "                 hue='tumor', plot_kws=dict(alpha=.4))\n",
    "\n",
    "#you can ignore this\n",
    "handles = g._legend_data.values()\n",
    "g.fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "g._legend.remove()\n",
    "g.fig.suptitle('Pair Plot', weight='bold', size='xx-large')\n",
    "g.fig.subplots_adjust(top=0.96, bottom=0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use PCA to identify axes (eigen vectors) that will retain the most information (variance) from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code from last week did this from scratch, we are going to use a package from sklearn to do PCA this week\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PerformPCA(X):\n",
    "    \"\"\"\n",
    "    Uses sklearn PCA tool to perform PCA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    n_dimensions: Number of PCs to fit\n",
    "    \n",
    "    output:\n",
    "    X_pca: Pandas dataframe with column titles of PC1,...,PCn\n",
    "    \"\"\"\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    pca = PCA()\n",
    "    pca.fit(X_standardized)\n",
    "    X_pca_array = pca.transform(X_standardized)\n",
    "    column_names = ['PC{}'.format(i+1) for i in range(X_pca_array.shape[1])] \n",
    "    X_pca = pd.DataFrame(X_pca_array, columns=column_names)\n",
    "    return X_pca, pca\n",
    "\n",
    "pca_features, pca_results = PerformPCA(features)\n",
    "pca_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the PCs have been ordered from highest amount of variance explained to least: PC1 captures the most variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_values = np.arange(pca_results.n_components_) + 1\n",
    "plt.bar(PC_values, pca_results.explained_variance_ratio_);\n",
    "plt.title(\"Scree Plot\", weight='bold', size='xx-large' )\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Percent Variance Explained\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you see the diminishing returns in how many principle components to include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_breast = pd.concat([pca_features, tumor], axis=1)\n",
    "\n",
    "num_feats = 6\n",
    "g = sns.pairplot(data=pca_breast, corner=True, vars=pca_features.columns.to_list()[0:num_feats], \n",
    "                 hue='tumor', plot_kws=dict(alpha=.4))\n",
    "\n",
    "#you can ignore this\n",
    "handles = g._legend_data.values()\n",
    "g.fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "g._legend.remove()\n",
    "g.fig.suptitle('Pair Plot', weight='bold', size='xx-large')\n",
    "g.fig.subplots_adjust(top=0.96, bottom=0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we can capture most of the variance in our data from simply using PC1 and PC2, we can make a 2D plot with that information:\n",
    "\n",
    "Be careful with your interpretations here, we haven't necessarily done an analysis, we have just have adjusted the **perspective** that we are looking at the data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.scatterplot(data=pca_breast, x='PC1', y='PC2', hue='tumor', alpha=.6)\n",
    "sns.despine()\n",
    "#you can ignore this\n",
    "handles, _ = g.get_legend_handles_labels()\n",
    "g.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'])\n",
    "plt.title('PCA plot with PC1 and PC2', weight='bold', size='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember, PCA is unsupervised:\n",
    "Unsupervised means that we did **not** include any information about the benign vs. malignant information. \n",
    "What if our goal was to seperate the two classes or identify new data?\n",
    "What if we tried to use that information to inform our new axes?\n",
    "\n",
    "**Let's move on to Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning: \n",
    "\n",
    "If unsupervised learning was to help us indentify **patterns** in the data we couldn't otherwise see, supervised learning is used for making **predictions** about our data. What if we had a new tumor sample that we have measured using the same metrics that we have identified before (*e.g.* mean area, mean concavity), could we use our previous data to predict malignancy? \n",
    "\n",
    "Let's use Linear Discriminant Analysis to try and make these predictions, and as you will see, it has some similar utility to PCA. We will project our features onto a new dimension, trying to seperate our classes: benign and maliganant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def PerformLDA(X, y):\n",
    "    \"\"\"\n",
    "    Uses sklearn LinearDiscriminantAnalysis tool to perform LDA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    y: Pandas Series or Numpy Vector of target \n",
    "    n_dimensions: Number of LDs to fit\n",
    "    \n",
    "    output:\n",
    "    X_lda: Pandas dataframe with column titles of LD1,...,LDn\n",
    "    \"\"\"\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_standardized,y)\n",
    "    X_lda_array = lda.transform(X_standardized)\n",
    "    column_names = ['LD{}'.format(i+1) for i in range(X_lda_array.shape[1])] \n",
    "    X_lda = pd.DataFrame(X_lda_array, columns=column_names)\n",
    "    return X_lda, lda\n",
    "\n",
    "lda_features, lda_results = PerformLDA(features, tumor)\n",
    "lda_breast = lda_features.join(tumor)\n",
    "lda_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we've reduced the dimensionality with LDA, let's compare it visually to PCA. \n",
    "\n",
    "These 4 plots show the exact same data, but it might be easier to interpret one over another. Feel free to draw your conclusions from any of them (and maybe think about what conclusions are easier to draw from what visualizations!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "sns.swarmplot(ax=axs[0], data=lda_breast[lda_breast['tumor']==0], x='LD1', color=sns.color_palette()[0], alpha=.7)\n",
    "sns.swarmplot(ax=axs[0], data=lda_breast[lda_breast['tumor']==1], x='LD1', color=sns.color_palette()[1], alpha=.7)\n",
    "sns.despine(left=True)\n",
    "sns.swarmplot(ax=axs[1], data=pca_breast[pca_breast['tumor']==0], x='PC1', color=sns.color_palette()[0], alpha=.7)\n",
    "sns.swarmplot(ax=axs[1], data=pca_breast[pca_breast['tumor']==1], x='PC1', color=sns.color_palette()[1], alpha=.7)\n",
    "sns.despine(left=True)\n",
    "axs[0].text(-6, .2, 'LDA', weight='bold', size='xx-large')\n",
    "axs[1].text(-15, .2, 'PCA', weight='bold', size='xx-large')\n",
    "axs[0].set_xlim(-6,6)\n",
    "axs[1].set_xlim(-15,15)\n",
    "fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "fig.suptitle('Swarm Plot', weight='bold', size='xx-large')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "sns.boxplot(ax=axs[0], data=lda_breast.replace({'tumor': {0: 'benign', 1: 'malignant'}}), \n",
    "              x='LD1', y='tumor', color='white', fliersize=0)\n",
    "sns.swarmplot(ax=axs[0], data=lda_breast.replace({'tumor': {0: 'benign', 1: 'malignant'}}), \n",
    "              x='LD1', y='tumor', alpha=.7)\n",
    "\n",
    "sns.despine(left=True)\n",
    "sns.boxplot(ax=axs[1], data=pca_breast.replace({'tumor': {0: 'benign', 1: 'malignant'}}), \n",
    "              x='PC1', y='tumor', color='white', fliersize=0)\n",
    "sns.swarmplot(ax=axs[1], data=pca_breast.replace({'tumor': {0: 'benign', 1: 'malignant'}}), \n",
    "              x='PC1', y='tumor', alpha=.7)\n",
    "sns.despine(left=True)\n",
    "axs[0].text(-6, .5, 'LDA', weight='bold', size='xx-large')\n",
    "axs[1].text(-15, .5, 'PCA', weight='bold', size='xx-large')\n",
    "axs[0].set_xlim(-6,6)\n",
    "axs[1].set_xlim(-15,15)\n",
    "fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "fig.suptitle('Swarm Plot with Box Plot', weight='bold', size='xx-large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "sns.histplot(ax=axs[0], data=lda_breast, x='LD1', hue='tumor', alpha=.4, fill=True, legend=False)\n",
    "sns.despine()\n",
    "sns.histplot(ax=axs[1], data=pca_breast, x='PC1', hue='tumor', alpha=.4, fill=True, legend=False)\n",
    "sns.despine()\n",
    "axs[0].text(-5.6, 60, 'LDA', weight='bold', size='xx-large')\n",
    "axs[1].text(-14, 60, 'PCA', weight='bold', size='xx-large')\n",
    "axs[0].set_xlim(-6,6)\n",
    "axs[1].set_xlim(-15,15)\n",
    "fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "fig.suptitle('Histograms', weight='bold', size='xx-large')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "sns.kdeplot(ax=axs[0], data=lda_breast, x='LD1', hue='tumor', alpha=.4, fill=True, legend=False)\n",
    "sns.despine()\n",
    "sns.kdeplot(ax=axs[1], data=pca_breast, x='PC1', hue='tumor', alpha=.4, fill=True, legend=False)\n",
    "sns.despine()\n",
    "axs[0].text(-5.6, .15, 'LDA', weight='bold', size='xx-large')\n",
    "axs[1].text(-14, .08, 'PCA', weight='bold', size='xx-large')\n",
    "axs[0].set_xlim(-6,6)\n",
    "axs[1].set_xlim(-15,15)\n",
    "fig.legend(handles=handles, loc='lower center', ncol=2, labels=['benign','malignant'], frameon=False)\n",
    "fig.suptitle('Kernel Density Plot', weight='bold', size='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try to use LDA to predict whether or not a tumor is benign or malignant. \n",
    "\n",
    "First we will split our data into an 80% training set and a 20% test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), \n",
    "                                                    tumor, test_size=split, random_state=5)\n",
    "\n",
    "print(f\"My training set has {X_train.shape[0]} observations, where my test set has {X_test.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we evaluate our classification? \n",
    "\n",
    "An ubiquitous metric is \"accuracy\" which is the percentage of the set (training or test) that the algorithm was able to predict correctly. The training set is the data where the algorithm \"sees\" the target/response class. The test set is the one where we withhold the class data until the algorithm makes the prediction.\n",
    "\n",
    "Remember: we have the ground truth of benign v. malignant to compare to, and we just need to give the algorithm the features. Please do be critical of any biases for your ground truth data, as your algorithm will only be as effective as the data you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerformLDA(X, y):\n",
    "    \"\"\"\n",
    "    Uses sklearn LinearDiscriminantAnalysis tool to perform LDA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    y: Pandas Series or Numpy Vector of target \n",
    "    n_dimensions: Number of LDs to fit\n",
    "    \n",
    "    output:\n",
    "    X_lda: Pandas dataframe with column titles of LD1,...,LDn\n",
    "    \"\"\"\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X,y)\n",
    "    X_lda_array = lda.transform(X)\n",
    "    column_names = ['LD{}'.format(i+1) for i in range(X_lda_array.shape[1])] \n",
    "    X_lda = pd.DataFrame(X_lda_array, columns=column_names)\n",
    "    return X_lda, lda\n",
    "\n",
    "lda_train, lda_model = PerformLDA(X_train, y_train)\n",
    "train_accuracy = lda_model.score(X_train, y_train)\n",
    "print(f\"Training classification accuracy of {train_accuracy*100:0.1f}%\")\n",
    "test_accuracy = lda_model.score(X_test, y_test)\n",
    "print(f\"Test classification accuracy of {test_accuracy*100:0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(lda_model.transform(X_train), columns=['LD1'])\n",
    "train['tumor'] = y_train.values\n",
    "train['train'] = 'train'\n",
    "test = pd.DataFrame(lda_model.transform(X_test), columns=['LD1'])\n",
    "test['tumor'] = y_test.values\n",
    "test['train'] = 'test'\n",
    "test['predict'] = lda_model.predict(X_test)\n",
    "\n",
    "\n",
    "total_set = pd.concat([train, test], ignore_index=True)\n",
    "total_set = total_set.replace({'tumor': {0: 'benign', 1: 'malignant'}})\n",
    "total_set = total_set.replace({'predict': {0: 'benign', 1: 'malignant'}})\n",
    "\n",
    "sns.swarmplot(data=total_set, x='LD1', y='train', hue='tumor', hue_order=['benign','malignant'],alpha=.7)\n",
    "# sns.swarmplot(data=total_set[total_set['guess']!=total_set['guess']], x='LD1', y='train', color='red', size=3, alpha=.2)\n",
    "sns.despine()\n",
    "misses=total_set[total_set['predict']!=total_set['tumor']].dropna()\n",
    "plt.axvline(misses['LD1'].min(), linestyle='--', color='r', linewidth=1)\n",
    "plt.axvline(misses['LD1'].max(), linestyle='--', color='r', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses[['LD1','tumor','predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
