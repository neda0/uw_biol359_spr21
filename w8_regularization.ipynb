{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359  |  Regularization\n",
    "### Spring 2021, Week 8\n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules and libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)}) #change figure size\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "np.random.seed(0)\n",
    "\n",
    "TITLE = {\n",
    "        'fontsize':20,\n",
    "        'fontweight':'bold'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates random *in silico* data according to a defined response. Since this is an *in silico* exercise, we know the underlying model, or gold standard. The data derives from a 2nd order system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    # Default - 2x^2 + 2\n",
    "    return 2*x**2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_data(function, noise_std, n=10, measurement_std=.2, initial_value=0, x_max=3):\n",
    "    \"\"\"\n",
    "    This function generates noisy data with a certain amount of error applied to the function response.\n",
    "    The error is normally distributed around the noise_std.\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, x_max, n) \n",
    "    x_noise = np.random.normal(0, measurement_std, len(x))\n",
    "    x += x_noise\n",
    "    y_noise = np.random.normal(0, noise_std, len(x))\n",
    "    y = function(x) + initial_value\n",
    "    y += y_noise\n",
    "    plt.plot(x, y, 'C0.', label='data')\n",
    "    x_func = np.linspace(0, max(x)+measurement_std)\n",
    "    y_func = function(x_func) + initial_value\n",
    "    plt.plot(x_func, y_func, 'C0--', label='function')\n",
    "    plt.fill_between(x_func, y_func+noise_std, y_func-noise_std,\n",
    "                     alpha=0.1)          # Transparency of the fill\n",
    "    plt.title(r'$ y = 2x^2 + 2$ with noise (std of {})'.format(noise_std), fontdict=TITLE)\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.xlim(0, max(x)+measurement_std)\n",
    "    plt.show()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_model(x, y, x_model, y_model, title = ''):\n",
    "    \"\"\"\n",
    "    Plotter function.\n",
    "    \"\"\"\n",
    "    plt.plot(x,y, 'o', label='data')\n",
    "    plt.plot(x_model, y_model, '--', label='model')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.xlim(0, max(x))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Standardize the data\n",
    "Procedural note: **standardization** of data (taking the z-score by mean-centering and scaling data by its standard deviation) is required before performing regularization. An example of standardization is shown below. This code walks through the mathematics \"under the hood\" of `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_plot(x):\n",
    "    sns.distplot(x, label='Data')\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    x_zscore = (x - mean)/(std)\n",
    "    zscored_mean = np.mean(x_zscore)\n",
    "    zscored_std = np.std(x_zscore)\n",
    "    sns.distplot(x_zscore, label='Standardized')\n",
    "    plt.xlabel('x values')\n",
    "    plt.ylabel('frequencies')\n",
    "    plt.axvline(mean, color='C0', linestyle='-')\n",
    "    plt.axvline(mean + std, color='C0', linestyle='--')\n",
    "    plt.axvline(mean - std, color='C0', linestyle='--')\n",
    "    plt.axvline(zscored_mean, color='C1', linestyle='-')\n",
    "    plt.axvline(zscored_mean+zscored_std, color='C1', linestyle='--')\n",
    "    plt.axvline(zscored_mean-zscored_std, color='C1', linestyle='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "x = np.random.normal(6, 3, 300)\n",
    "zscore_plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_feature_example(x, y, regularization = None, reg_alpha=1, degrees=6):\n",
    "    \"\"\"\n",
    "    Perform regularization on a polynomial feature set. \n",
    "    \"\"\"\n",
    "    poly_transform = PolynomialFeatures(degree=degrees, include_bias = False)\n",
    "    x_poly = poly_transform.fit_transform(x.reshape(-1,1))\n",
    "    \n",
    "    #Regularization techniques need to be scaled in order to work properly\n",
    "    x_scaler = StandardScaler().fit(x_poly)\n",
    "    y_scaler = StandardScaler().fit(y.reshape(-1,1))\n",
    "    x_poly_z = x_scaler.transform(x_poly)\n",
    "    y_z = y_scaler.transform(y.reshape(-1,1))\n",
    "    \n",
    "    #Code to perform the model fitting and parameter estimation\n",
    "    if regularization is None:\n",
    "        #Least Squares problem\n",
    "        plt.suptitle('Linear Regression', fontsize=20, fontweight='bold')\n",
    "        lm_poly = linear_model.LinearRegression(fit_intercept=True)\n",
    "        lm_poly.fit(x_poly_z,y_z)\n",
    "        \n",
    "    elif regularization is 'L1':\n",
    "        #LASSO problem\n",
    "        plt.suptitle('LASSO', fontsize=20, fontweight='bold')       \n",
    "        lm_poly = linear_model.Lasso(alpha = reg_alpha, max_iter=1e8, fit_intercept=True)\n",
    "        lm_poly.fit(x_poly_z,y_z)    \n",
    "        \n",
    "    elif regularization is 'L2':\n",
    "        #ridge problem\n",
    "        plt.suptitle('Ridge', fontsize=20, fontweight='bold')\n",
    "        lm_poly = linear_model.Ridge(alpha = reg_alpha, max_iter=1e5, fit_intercept=True)\n",
    "        lm_poly.fit(x_poly_z,y_z)\n",
    "        \n",
    "    x_model = np.linspace(min(x), max(x), 150).reshape(-1,1)\n",
    "    x_model_transform = poly_transform.fit_transform(x_model)\n",
    "    x_model_transform_z = x_scaler.transform(x_model_transform)\n",
    "    \n",
    "    \n",
    "    y_model = lm_poly.predict(x_model_transform_z)*y_scaler.scale_ + y_scaler.mean_\n",
    "    \n",
    "    #********************************************************************************\n",
    "    # Coefficients from scaled model can be transformed back into original units\n",
    "    # This code is outside the scope of this class and can be ignored. \n",
    "    \n",
    "    unscaled_coefficients = (lm_poly.coef_ * y_scaler.scale_ / x_scaler.scale_).flatten()\n",
    "    \n",
    "    poly_terms = [r'$({0:.3f})x ^ {{{1}}}$'.format(coef, i+1) for i, coef in enumerate(unscaled_coefficients)\n",
    "                 if coef != 0]\n",
    "    \n",
    "    unscaled_intercept = lm_poly.intercept_*y_scaler.scale_ + y_scaler.mean_ \\\n",
    "                            - sum(unscaled_coefficients*x_scaler.mean_)\n",
    "        \n",
    "    intercept_str = r'${0:.1f} + $'.format(unscaled_intercept[0])\n",
    "    title =  intercept_str + r'$+$'.join(poly_terms)\n",
    "    #********************************************************************************\n",
    "    \n",
    "    plot_model(x_data, y_data, x_model, y_model, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Plot the *in silico* data and the true model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = generate_noisy_data(quadratic, 1, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the SLR coefficients for the *in silico* data generated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_feature_example(x_data, y_data, degrees=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the LASSO regression coefficients for the *in silico* data generated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_feature_example(x_data, y_data, regularization='L1', reg_alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculate the Ridge regression coefficients for the *in silico* data generated above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_feature_example(x_data, y_data, regularization='L2', reg_alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Significantly increase the number of observations, *n*, and re-calculate the regression coefficients. \n",
    "When the number of samples, *n*, is high, we do not impose the risk of overfitting as it is unlikely we would propose a model with *n*-degrees of freedom when *n>>0*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_data, y_data = generate_noisy_data(quadratic, 1, n=300)\n",
    "polynomial_feature_example(x_data, y_data)\n",
    "polynomial_feature_example(x_data, y_data, regularization='L1', reg_alpha= .1)\n",
    "polynomial_feature_example(x_data, y_data, regularization='L2', reg_alpha = .1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
