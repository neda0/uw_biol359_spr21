{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359  |  Linear Regression\n",
    "### Spring 2021, Week 7\n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import sklearn as sk\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)}) \n",
    "sns.set_style(\"whitegrid\",  {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "\n",
    "#current commit doesn't have it in a raw csv file\n",
    "source_url = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/1a19e36ba583887a4630b1f821e3a53d5a4ffb76/data-raw/penguins_raw.csv'\n",
    "penguins =  pd.read_csv(source_url)\n",
    "\n",
    "description_url = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/DESCRIPTION'\n",
    "for line in urllib.request.urlopen(description_url):\n",
    "    print(line.decode('utf-8')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_penguins(penguin_df, \n",
    "    cols = ['Species', \n",
    "            'Region', \n",
    "            'Island', \n",
    "            'Culmen Length (mm)', \n",
    "            'Culmen Depth (mm)', \n",
    "            'Flipper Length (mm)', \n",
    "            'Body Mass (g)', \n",
    "            'Sex']):\n",
    "    penguin_tidy = penguin_df[cols]\n",
    "    penguin_tidy = penguin_tidy.dropna() \n",
    "    return penguin_tidy\n",
    "    \n",
    "penguins = clean_penguins(penguins)\n",
    "penguins.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=penguins, hue='Species', markers=[\"o\", \"s\", \"D\"], corner=True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA and LDA on penguins, for the curious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def PerformPCA(X):\n",
    "    \"\"\"\n",
    "    Uses sklearn PCA tool to perform PCA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    \n",
    "    output:\n",
    "    X_pca: Pandas dataframe with column titles of PC1,...,PCn\n",
    "    pca: sklearn's PCA object\n",
    "    \"\"\"\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    pca = PCA()\n",
    "    pca.fit(X_standardized)\n",
    "    X_pca_array = pca.transform(X_standardized)\n",
    "    column_names = ['PC{}'.format(i+1) for i in range(X_pca_array.shape[1])] \n",
    "    X_pca = pd.DataFrame(X_pca_array, columns=column_names)\n",
    "    return X_pca, pca\n",
    "\n",
    "\n",
    "def PerformLDA(X, y):\n",
    "    \"\"\"\n",
    "    Uses sklearn LinearDiscriminantAnalysis tool to perform LDA\n",
    "    input:\n",
    "    X: Pandas Dataframe or Numpy Array of features\n",
    "    y: Pandas Series or Numpy Vector of target \n",
    "    \n",
    "    output:\n",
    "    X_lda: Pandas dataframe with column titles of LD1,...,LDn\n",
    "    lda: sklearn's LinearDiscriminantAnalysis object\n",
    "    \"\"\"\n",
    "    X_standardized = StandardScaler().fit_transform(X)\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_standardized,y)\n",
    "    X_lda_array = lda.transform(X_standardized)\n",
    "    column_names = ['LD{}'.format(i+1) for i in range(X_lda_array.shape[1])] \n",
    "    X_lda = pd.DataFrame(X_lda_array, columns=column_names)\n",
    "    return X_lda, lda\n",
    "\n",
    "\n",
    "def makeplots(df, feature_col, response_col):\n",
    "    \"\"\"\n",
    "    Makes PCA and LDA plots using functions: PerformPCA and PerformLDA\n",
    "    input:\n",
    "    df: data dataframe\n",
    "    feature_col: list of strings to use as features in df\n",
    "    response_col: string of response column in df\n",
    "    \n",
    "    output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    features = df[feature_col]\n",
    "    response = df[response_col]\n",
    "    pca_features, pca_results = PerformPCA(features)\n",
    "    pca_plotting = pca_features.join(response)\n",
    "    lda_features, lda_results = PerformLDA(features, response)\n",
    "    lda_plotting = lda_features.join(response)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    g1 = sns.scatterplot(data=pca_plotting, x='PC1', y='PC2', hue='Species',\n",
    "                         style='Species', markers=[\"o\", \"s\", \"D\"], ax=ax[0],  legend=False, alpha=0.75, s=66)\n",
    "    sns.despine()\n",
    "    ax[0].set_title('PCA plot with PC1 and PC2', fontsize=18, fontweight='bold')    \n",
    "    g2 = sns.scatterplot(data=lda_plotting, x='LD1', y='LD2', hue='Species', \n",
    "                         style='Species', markers=[\"o\", \"s\", \"D\"], ax=ax[1], legend=True, alpha=0.75, s=66)\n",
    "    sns.despine()\n",
    "    g2.legend(fontsize = 14, \n",
    "              title=\"Species\", \n",
    "              title_fontsize = 14, \n",
    "              loc='lower left', bbox_to_anchor=(-1.35, -.4),\n",
    "              facecolor = 'white', ncol=3, frameon=False)\n",
    "    ax[0].set_box_aspect(1)\n",
    "    ax[1].set_box_aspect(1)\n",
    "    ax[1].set_title('LDA plot with LD1 and LD2', fontsize=18, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "makeplots(penguins, ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)'], 'Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "feature_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n",
    "response_col = 'Body Mass (g)'\n",
    "\n",
    "\n",
    "def linear_regression(df, feature_cols, response_col, standardized = True):\n",
    "    \"\"\"\n",
    "    Use linear_model to run a linear regression using sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    X = df[feature_cols]\n",
    "    y = df[response_col]\n",
    "    if standardized:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        y = StandardScaler().fit_transform(y.values.reshape(-1, 1))\n",
    "    regression = linear_model.LinearRegression() \n",
    "    regression.fit(X,y)\n",
    "    \n",
    "    try:\n",
    "        print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_))\n",
    "    except TypeError:\n",
    "        print('Intercept of MLR model is {0:0.2f}'.format(regression.intercept_[0]))\n",
    "    print('Regression Coefficients: ')\n",
    "    for feature, coef in zip(feature_cols, regression.coef_.flatten()):\n",
    "        print(f'{feature} ~ {coef:.2f}')\n",
    "    return regression.predict(X)\n",
    "\n",
    "print(' Normalized: ')\n",
    "y_pred_norm = linear_regression(penguins, feature_cols, response_col)\n",
    "\n",
    "print('\\n Not Normalized: ')\n",
    "y_pred = linear_regression(penguins, feature_cols, response_col, standardized=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_distribution(true, pred, hue=None):\n",
    "    ax = plt.subplots(figsize=(12, 8))\n",
    "    error = true-pred\n",
    "    if hue is not None: \n",
    "        sns.kdeplot(error, hue=hue, shade=True, alpha=.2)\n",
    "    else:\n",
    "        sns.kdeplot(error, shade=True, alpha=.2)\n",
    "    sns.despine()\n",
    "\n",
    "    plt.xlabel(r'Residuals ($\\epsilon$)')\n",
    "    plt.title('Error')\n",
    "    plt.show()\n",
    "    \n",
    "def parity_plot(true, pred, title='', hue=None):\n",
    "    \"\"\"\n",
    "    plot true vs the predicted data\n",
    "    inputs: 2 list-like (arrays) data structures\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10, 8))\n",
    "    if hue is not None:\n",
    "        sns.scatterplot(true, pred, hue=hue)\n",
    "    else: \n",
    "        sns.scatterplot(true, pred)\n",
    "    min_value = min(min(true), min(pred))\n",
    "    max_value = max(max(true), max(pred))\n",
    "    plt.plot([min_value, max_value],[min_value, max_value], '--', label=\"parity\")\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    ax.set_box_aspect(1)\n",
    "    sns.despine()\n",
    "    plt.title('Parity Plot: {}'.format(title))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    error_distribution(true, pred, hue)\n",
    "\n",
    "y = penguins[response_col]\n",
    "parity_plot(y.values, y_pred, title='Body Weight Predictions', hue=penguins['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.Species.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
